{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688b3350-c17f-46cb-9370-0341b5e4ad23",
   "metadata": {},
   "source": [
    "# Train a model for classifying tissue samples into benign vs malign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9411c72-065b-4cdf-9420-6d07685f60ef",
   "metadata": {},
   "source": [
    "## Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b33f0d-e5c7-43df-bbe8-c916882916e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow version: 9.4.0\n"
     ]
    }
   ],
   "source": [
    "# download from urls\n",
    "import urllib.request\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Uncomment the following line to install Pillow if not already installed\n",
    "# !pip install --upgrade pillow\n",
    "\n",
    "# Verify Pillow installation\n",
    "from PIL import Image\n",
    "import PIL\n",
    "print(\"Pillow version:\", PIL.__version__)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ca917-aba1-4995-a5a3-0adb0859d367",
   "metadata": {},
   "source": [
    "## Get the data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2812368-7a0a-4e11-ab38-54e6e98f51df",
   "metadata": {},
   "source": [
    "### Download the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb10980-850d-448f-8320-28587b703453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_01.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_02.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_03.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_04.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_05.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_06.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_07.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_08.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_09.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_10.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_11.tar.gz...\n",
      "downloading/home/crisrbarreram/Documents/ccir_demo/imgs/images_12.tar.gz...\n",
      "Download complete. Please check the checksums\n"
     ]
    }
   ],
   "source": [
    "# Download the 56 zip files in Images_png in batches\n",
    "# URLs for the zip files\n",
    "links = [\n",
    "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
    "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
    "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
    "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
    "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
    "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
    "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
    "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
    "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
    "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
    "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
    "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
    "]\n",
    "\n",
    "\n",
    "for idx, link in enumerate(links):\n",
    "    fn = '/home/crisrbarreram/Documents/ccir_demo/imgs/images_%02d.tar.gz' % (idx+1)\n",
    "    print('downloading'+fn+'...')\n",
    "    urllib.request.urlretrieve(link, fn)  # download the zip file\n",
    "\n",
    "\n",
    "print(\"Download complete. Please check the checksums\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf4708-15c0-4897-af03-a726ae7f76b8",
   "metadata": {},
   "source": [
    "### Define the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d335f0-1491-4b8f-914c-7ea2703ac7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = '/home/cbarr23/Documents/ccir_demo/imgs/'\n",
    "csv_path = '/home/cbarr23/Documents/ccir_demo/Data_Entry_2017_v2020.csv'\n",
    "output_dir = '/home/cbarr23/Documents/ccir_demo/processed/'\n",
    "image_dir = '/home/cbarr23/Documents/ccir_demo/imgs/images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba63e0b2-60cf-4139-b379-367df7b1ff75",
   "metadata": {},
   "source": [
    "### Unpack the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a82f601-0620-40bb-94e3-3c99f01df01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacked images_01.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_01\n",
      "Unpacked images_02.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_02\n",
      "Unpacked images_03.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_03\n",
      "Unpacked images_05.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_05\n",
      "Unpacked images_10.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_10\n",
      "Unpacked images_09.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_09\n",
      "Unpacked images_12.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_12\n",
      "Unpacked images_06.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_06\n",
      "Unpacked images_07.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_07\n",
      "Unpacked images_04.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_04\n",
      "Unpacked images_08.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_08\n",
      "Unpacked images_11.tar.gz into /home/cbarr23/Documents/ccir_demo/imgs/images_11\n"
     ]
    }
   ],
   "source": [
    "# Unpack all .tar.gz files into individual subdirectories\n",
    "tar_files = [f for f in os.listdir(data_dir) if f.endswith('.tar.gz')]\n",
    "for tar_file in tar_files:\n",
    "    tar_path = os.path.join(data_dir, tar_file)\n",
    "    subdir = os.path.join(data_dir, tar_file[:-7])  # Create subdirectory based on tar file name\n",
    "    os.makedirs(subdir, exist_ok=True)\n",
    "    with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=subdir)\n",
    "    print(f'Unpacked {tar_file} into {subdir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1f6633e-d2c2-4595-bb19-190d090fced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for processed data\n",
    "os.makedirs(os.path.join(output_dir, 'train/normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'train/pneumonia'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test/normal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test/pneumonia'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783dcc76-0475-4b31-9951-fe5db6205e2b",
   "metadata": {},
   "source": [
    "### Load the csv file for identifying the labels for normal vs pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f0d7f7e-9fb0-48c3-8be7-2738d0b0d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ab7809-e12d-48a5-a7df-b4bfa512794e",
   "metadata": {},
   "source": [
    "### filter out for Pneumonia vs Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "285f0bd6-5554-4846-8e97-093bdeacc83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV and filter images with labels 'No Finding' and 'Pneumonia'\n",
    "df = pd.read_csv(csv_path)\n",
    "filtered_df = df[df['Finding Labels'].isin(['No Finding', 'Pneumonia'])].copy()\n",
    "\n",
    "# Map 'No Finding' to 'normal' and 'Pneumonia' to 'pneumonia'\n",
    "filtered_df.loc[:, 'label'] = filtered_df['Finding Labels'].map({'No Finding': 'normal', 'Pneumonia': 'pneumonia'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ae5d2-5a66-4bef-bbf1-3d9ef7bb8dce",
   "metadata": {},
   "source": [
    "### Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20b35cc1-f2a8-4180-91a6-db3b80b16b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "train_df, test_df = train_test_split(filtered_df, test_size=0.2, stratify=filtered_df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b61ab3a-d5c9-4ff6-9460-1b575554d901",
   "metadata": {},
   "source": [
    "### copy images to corresponding folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f55197af-cfbb-4b2c-b3a7-6461cf4d9a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been successfully filtered and organized.\n"
     ]
    }
   ],
   "source": [
    "# Function to copy images to their respective directories\n",
    "def copy_images(df, split):\n",
    "    for _, row in df.iterrows():\n",
    "        label = row['label']\n",
    "        image_path = os.path.join(image_dir, row['Image Index'])\n",
    "        if os.path.exists(image_path):\n",
    "            shutil.copy(image_path, os.path.join(output_dir, split, label, row['Image Index']))\n",
    "\n",
    "\n",
    "# Copy images to train and test directories\n",
    "copy_images(train_df, 'train')\n",
    "copy_images(test_df, 'test')\n",
    "\n",
    "\n",
    "print(\"Images have been successfully filtered and organized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad47e74-951e-472d-b097-1a165a64eb05",
   "metadata": {},
   "source": [
    "## Get the model ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668947d-b868-4b62-8317-f1d0f68703a3",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5e544f6-386a-4743-8c1c-8e4f93fc0b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for training\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc6f8d9-abac-4ca0-b0e1-77307ade3a16",
   "metadata": {},
   "source": [
    "### Generate the data for the DL model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99ea8495-5332-46f3-9db4-04c4f34c08db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48546 images belonging to 2 classes.\n",
      "Found 12137 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'train'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'test'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c86f46-1480-4a76-801a-c6fc357f1b75",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94a046ab-1104-4bc5-b8bf-2ae09e3876bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4eb9e-5098-463b-b1ca-37ce92324162",
   "metadata": {},
   "source": [
    "### Combine the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e6b280d-39cd-4b31-afc5-66ab1741d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7653a8c6-af70-4e4b-ba63-88bb5f91102e",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2789c2-adc3-4653-bfda-d20012480cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 07:14:22.447530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1518/1518 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 07:25:43.732492: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1518/1518 [==============================] - 805s 530ms/step - loss: 0.0423 - accuracy: 0.9941 - val_loss: 0.0333 - val_accuracy: 0.9947\n",
      "Epoch 2/10\n",
      "1518/1518 [==============================] - 803s 529ms/step - loss: 0.0359 - accuracy: 0.9947 - val_loss: 0.0358 - val_accuracy: 0.9947\n",
      "Epoch 3/10\n",
      "1518/1518 [==============================] - 801s 527ms/step - loss: 0.0354 - accuracy: 0.9947 - val_loss: 0.0335 - val_accuracy: 0.9947\n",
      "Epoch 4/10\n",
      "1518/1518 [==============================] - 797s 525ms/step - loss: 0.0359 - accuracy: 0.9947 - val_loss: 0.0329 - val_accuracy: 0.9947\n",
      "Epoch 5/10\n",
      "1518/1518 [==============================] - 805s 530ms/step - loss: 0.0349 - accuracy: 0.9947 - val_loss: 0.0338 - val_accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "1518/1518 [==============================] - 807s 531ms/step - loss: 0.0489 - accuracy: 0.9946 - val_loss: 0.0331 - val_accuracy: 0.9947\n",
      "Epoch 7/10\n",
      "1518/1518 [==============================] - 796s 525ms/step - loss: 0.0352 - accuracy: 0.9947 - val_loss: 0.0336 - val_accuracy: 0.9947\n",
      "Epoch 8/10\n",
      "1518/1518 [==============================] - 801s 527ms/step - loss: 0.0354 - accuracy: 0.9947 - val_loss: 0.0334 - val_accuracy: 0.9947\n",
      "Epoch 9/10\n",
      "1518/1518 [==============================] - 804s 530ms/step - loss: 0.0346 - accuracy: 0.9947 - val_loss: 0.0352 - val_accuracy: 0.9947\n",
      "Epoch 10/10\n",
      "1280/1518 [========================>.....] - ETA: 1:45 - loss: 0.0351 - accuracy: 0.9946"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=epochs, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7c764-b355-494f-889c-f6e81c3a47b7",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c75e57a-5ec7-46c6-96f3-64951c2da6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('/home/cbarr23/Documents/ccir_demo/model/cxr_classification_epoch_10_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa9bac-94d2-4863-89cf-994cac3fc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model('/home/cbarr23/Documents/ccir_demo/model/cxr_classification_epoch_10_model.h5')\n",
    "\n",
    "# Set the last convolutional layer name\n",
    "last_conv_layer_name = 'conv2d_5'\n",
    "\n",
    "# Get a batch of images and labels from the test set\n",
    "test_images, test_labels = next(test_generator)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Convert predictions to binary labels\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Function to display images with true and predicted labels\n",
    "def display_images_with_predictions(images, true_labels, predicted_labels, num_images=5):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(num_images):\n",
    "        if i >= len(images):  # Check if index is within range\n",
    "            break\n",
    "        ax = plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        true_label = 'Pneumonia' if true_labels[i] == 1 else 'Normal'\n",
    "        predicted_label = 'Pneumonia' if predicted_labels[i] == 1 else 'Normal'\n",
    "        plt.title(f\"True: {true_label}\\nPred: {predicted_label}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Grad-CAM function\n",
    "def get_gradcam_heatmap(model, img_array, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "    \n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Function to display Grad-CAM\n",
    "def display_gradcam(img_array, heatmap, alpha=0.4):\n",
    "    img = np.uint8(255 * img_array)\n",
    "    \n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = plt.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "    \n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display random samples from the test set with Grad-CAM heatmaps\n",
    "num_images = 4\n",
    "correct_indices = np.where(test_labels == predicted_labels)[0]\n",
    "incorrect_indices = np.where(test_labels != predicted_labels)[0]\n",
    "\n",
    "# Display correct predictions with Grad-CAM\n",
    "if len(correct_indices) > 0:\n",
    "    print(\"Correct Predictions with Grad-CAM:\")\n",
    "    for idx in random.sample(correct_indices.tolist(), min(num_images, len(correct_indices))):\n",
    "        img_array = np.expand_dims(test_images[idx], axis=0)\n",
    "        heatmap = get_gradcam_heatmap(model, img_array, last_conv_layer_name)\n",
    "        display_images_with_predictions([test_images[idx]], [test_labels[idx]], [predicted_labels[idx]], 1)\n",
    "        display_gradcam(test_images[idx], heatmap)\n",
    "else:\n",
    "    print(\"No correct predictions to display.\")\n",
    "\n",
    "# Display incorrect predictions with Grad-CAM\n",
    "if len(incorrect_indices) > 0:\n",
    "    print(\"Incorrect Predictions with Grad-CAM:\")\n",
    "    for idx in random.sample(incorrect_indices.tolist(), min(num_images, len(incorrect_indices))):\n",
    "        img_array = np.expand_dims(test_images[idx], axis=0)\n",
    "        heatmap = get_gradcam_heatmap(model, img_array, last_conv_layer_name)\n",
    "        display_images_with_predictions([test_images[idx]], [test_labels[idx]], [predicted_labels[idx]], 1)\n",
    "        display_gradcam(test_images[idx], heatmap)\n",
    "else:\n",
    "    print(\"No incorrect predictions to display.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (image_processing_env)",
   "language": "python",
   "name": "image_processing_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
